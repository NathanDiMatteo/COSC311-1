{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057fe2c0-bc42-4575-bf03-3a0cc49a8f2e",
   "metadata": {},
   "source": [
    "# Project 1; Large Scale Data Analysis; Sam Disharoon & Nathan Dimatteo\n",
    "\n",
    "## Objective\n",
    "\n",
    "Take 3 sets of data that are fairly large in size and perform various tasks on them.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- (a) What type of population is being sampled? What are the “things” getting measured – usually one per row of data.\n",
    "- (b) What features does each sample have, i.e. what is being measured?\n",
    "- (c) Are the features quantitative or qualitative? Ordinal or nominal? Continuous or discrete?\n",
    "- (d) Is the data “complete” or do some of the samples have null or absent values for certain features? Why are these samples still useful? Why are they incomplete?\n",
    "- (e) Why are these features chosen to be part of the dataset?\n",
    "- (f) What are some other features that are not included but that you think might make sense to include for this dataset?\n",
    "- (g) Give at least one way that you can pivot the dataset to get a slightly different representation of some values. Explain what this is and how you would use it for a visualization.\n",
    "- (h) Identify any possible relationships between features included in the data: which ones are likely to affect others?\n",
    "    - i. Show at least one plot or visualization to illustrate this (possible) relationship.\n",
    "    - ii. What numerical or statistical techniques might you consider using to determine whether the relationship is reliable?\n",
    "    - iii. Are there external inferences you think might be possible? For instance, can you hypothesize a relationship with data not included in the dataset? Why or why not?\n",
    "- (i) What “extra” features can you perhaps compute from the data? For example, if you have data that includes product dates of purchase, you can “engineer” the data to construct the most popular products over various lengths of time (e.g. a particular holiday season). How might you use this information? Using the holiday example, you might try to correlate holiday sales of a product to some mainstream event that popularized it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecb46ac-d2c3-49b0-aa5e-e4a4e19a706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import pandas as p\n",
    "import numpy as n\n",
    "import seaborn as s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f4c4c-faf8-4b34-a3cd-bc8694dda95c",
   "metadata": {},
   "source": [
    "## Data Set 1; Pokemon :)\n",
    "\n",
    "This is the data set containing all the types of **pokemon** as of 10/1/2021.\n",
    "\n",
    "[csv link](https://www.kaggle.com/hamdallak/the-world-of-pokemons)\n",
    "\n",
    "### Useful Stats:\n",
    "- Size of set ~> 1045\n",
    "- Columns ~> 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faf37119-14a2-4145-ae6e-1d12a6dac9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon = p.read_csv('data/pokemon.csv', header = None, skipinitialspace = True, encoding = 'latin-1')\n",
    "len(pokemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc220fd0-a635-4fdf-9e06-387cf5896743",
   "metadata": {},
   "source": [
    "## Data Set 2; Stock Exchange Data\n",
    "\n",
    "This is the data set containing the stock market information for 14 unique exchanges over the span of 12-31-1965 to 06-03-2021.\n",
    "\n",
    "There are 3 csv files, but for this project, we will only be using indexData.csv. This has all the null values and extra data that indexProcessed.csv does not. \n",
    "\n",
    "[csv link](https://www.kaggle.com/mattiuzc/stock-exchange-data)\n",
    "\n",
    "### Useful Stats:\n",
    "- Size of set ~> 112,458\n",
    "- Columns ~> 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7fb5b65-8bda-475d-9c92-f8417712e077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112458"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = p.read_csv('data/indexData.csv', header = None, skipinitialspace = True, encoding = 'latin-1')\n",
    "len(stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c9ffa-93fd-4f4b-bd2a-d296bed98c36",
   "metadata": {},
   "source": [
    "## Data Set 3; Crime in Baltimore\n",
    "\n",
    "This is the data set containing the selling price predictions of 14k 2nd hand cars.\n",
    "\n",
    "[csv link](https://www.kaggle.com/sohier/crime-in-baltimore)\n",
    "\n",
    "### Useful Stats:\n",
    "- Size of set ~> 276,530\n",
    "- Columns ~> 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "757d2e2e-52fd-4cf9-b599-5a915b07ccdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276530"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime = p.read_csv('data/crime.csv', header = None, skipinitialspace = True, encoding = 'latin-1', low_memory = False)\n",
    "len(crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c637f96-87d4-40fb-8c83-48fa4410bbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
